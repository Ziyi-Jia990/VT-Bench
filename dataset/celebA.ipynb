{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c94a136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å¼€å§‹æ‰§è¡Œ CelebA é¢„å¤„ç†æµç¨‹ (æ ‡ç­¾: Attractive)...\n",
      " æ­£åœ¨åŠ è½½æ ‡æ³¨æ–‡ä»¶ (list_attr_celeba.csv)...\n",
      " > æˆåŠŸåŠ è½½ 202599 æ¡è®°å½•ã€‚\n",
      " æ­£åœ¨å®šä¹‰ç‰¹å¾...\n",
      " > å·²å®šä¹‰ 0 ä¸ªè¿ç»­ç‰¹å¾ã€‚\n",
      " > å·²å®šä¹‰ 40 ä¸ªç±»åˆ«ç‰¹å¾ (åŒ…å«æ ‡ç­¾)ã€‚\n",
      " > ç›®æ ‡æ ‡ç­¾ (Label): Attractive\n",
      " æ­£åœ¨æŒ‰ 8:1:1 å¯¹ Attractive è¿›è¡Œåˆ†å±‚åˆ’åˆ†...\n",
      " > è®­ç»ƒé›†: 162079 æ ·æœ¬\n",
      " > éªŒè¯é›†: 20260 æ ·æœ¬\n",
      " > æµ‹è¯•é›†: 20260 æ ·æœ¬\n",
      " æ­£åœ¨ç­›é€‰æ’å®šç‰¹å¾...\n",
      " > å·²å°† 'Attractive' éš”ç¦»ä¸ºæ ‡ç­¾, ä¸ä½œä¸ºç‰¹å¾ã€‚\n",
      " > å‰©ä½™ 0 ä¸ªè¿ç»­ç‰¹å¾ã€‚\n",
      " > å‰©ä½™ 39 ä¸ªç±»åˆ«ç‰¹å¾ (è¡¨æ ¼å±æ€§)ã€‚\n",
      " æ­£åœ¨è½¬æ¢å›¾åƒè·¯å¾„ä¸ºç»å¯¹è·¯å¾„...\n",
      " æ­£åœ¨è¿‡æ»¤æ— æ•ˆè¡Œ (åŸºäºè·¯å¾„å’Œæ ‡ç­¾)...\n",
      " > è®­ç»ƒé›†ç§»é™¤ 0 è¡Œ\n",
      " > éªŒè¯é›†ç§»é™¤ 0 è¡Œ\n",
      " > æµ‹è¯•é›†ç§»é™¤ 0 è¡Œ\n",
      " æ­£åœ¨å¤„ç†ç¼ºå¤±å€¼/ç‰¹æ®Šç¼–ç ...\n",
      " > [CelebA ç‰¹å®š] è½¬æ¢å±æ€§ï¼šå°† -1 æ˜ å°„åˆ° 0...\n",
      " æ­£åœ¨å¤„ç†ç±»åˆ«ç‰¹å¾...\n",
      " > CelebA å±æ€§å·²ä¸º 0/1 ç¼–ç ï¼Œè·³è¿‡.cat.codesã€‚\n",
      " > æ­£åœ¨è®¡ç®—åŸºæ•° (Cardinalities)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_292101/4247396634.py:196: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if \"MISSING\" in all_values.unique():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 39 ä¸ªç±»åˆ«ç‰¹å¾çš„åŸºæ•° (éƒ¨åˆ†): [2, 2, 2, 2, 2]...\n",
      " æ­£åœ¨æ ‡å‡†åŒ–è¿ç»­ç‰¹å¾...\n",
      " > æ²¡æœ‰è¿ç»­ç‰¹å¾ï¼Œè·³è¿‡æ ‡å‡†åŒ–ã€‚\n",
      " æ­£åœ¨è½¬æ¢å›¾åƒ (JPG -> NPY, å¹¶ Resize åˆ° 224x224)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " > è½¬æ¢ è®­ç»ƒé›† å›¾åƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 162079/162079 [00:11<00:00, 14014.53it/s]\n",
      " > è½¬æ¢ éªŒè¯é›† å›¾åƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20260/20260 [00:00<00:00, 57746.67it/s]\n",
      " > è½¬æ¢ æµ‹è¯•é›† å›¾åƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20260/20260 [00:00<00:00, 55325.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > å›¾åƒè½¬æ¢å®Œæˆã€‚\n",
      "[Final] æ­£åœ¨ä¿å­˜æ‰€æœ‰å¤„ç†åçš„æ–‡ä»¶...\n",
      "------------------------------\n",
      "ğŸ‰ é¢„å¤„ç†å…¨éƒ¨å®Œæˆï¼ ğŸ‰\n",
      "è¾“å‡ºæ–‡ä»¶å·²ä¿å­˜åˆ°: ./features\n",
      " > æ ‡ç­¾ (Label): Attractive\n",
      " > è¡¨æ ¼ç‰¹å¾: 39 ä¸ªå…¶ä»–å±æ€§\n",
      " > åˆ’åˆ†æ¯”ä¾‹: 8:1:1 (åˆ†å±‚)\n",
      " > å›¾åƒå¤„ç†: å·²ç¼©æ”¾è‡³ 224x224 å¹¶è½¬ä¸º .npy\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "# Ensure PIL version compatibility (for resize)\n",
    "try:\n",
    "    # PIL 9.0.0+\n",
    "    LANCZOS_RESAMPLE = Image.Resampling.LANCZOS\n",
    "except AttributeError:\n",
    "    # Older PIL\n",
    "    LANCZOS_RESAMPLE = Image.LANCZOS\n",
    "\n",
    "# --- Configuration Area ---\n",
    "\n",
    "# *** 1. Paths have been modified according to your requirements ***\n",
    "DATA_ROOT = \"/mnt/hdd/jiazy/CelebA\"\n",
    "ATTR_FILE = os.path.join(DATA_ROOT, \"list_attr_celeba.csv\")\n",
    "BASE_IMAGE_DIR = os.path.join(DATA_ROOT, \"img_align_celeba\")\n",
    "\n",
    "# Output directory for processed files\n",
    "OUTPUT_DIR = \"./features\"\n",
    "\n",
    "# --- Key Changes ---\n",
    "# Target label\n",
    "LABEL_COLUMN = 'Attractive' \n",
    "# New: Image size\n",
    "IMAGE_SIZE = 224\n",
    "\n",
    "# --------------------\n",
    "\n",
    "def preprocess_celeba_flow(attr_file, base_image_dir, output_dir, label_column):\n",
    "    \"\"\"\n",
    "    Preprocess CelebA according to new user requirements (8:1:1 split, CSV loading, 224x224 resize)\n",
    "    \"\"\"\n",
    "    print(f\"Starting CelebA preprocessing pipeline (Label: {label_column})...\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # --- 1. ğŸ“– Load data (Step 1) ---\n",
    "    # *** 2. Modified: Load CSV instead of TXT, and no longer load partition file ***\n",
    "    print(\" Loading annotation file (list_attr_celeba.csv)...\")\n",
    "    try:\n",
    "        # Load .csv file\n",
    "        df_master = pd.read_csv(ATTR_FILE)\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: File not found {e.filename}.\")\n",
    "        print(\"Please ensure DATA_ROOT and ATTR_FILE are set correctly.\")\n",
    "        return\n",
    "    \n",
    "    # The partition and merge parts of the original script have been removed\n",
    "    print(f\" > Successfully loaded {len(df_master)} records.\")\n",
    "\n",
    "    # --- 2. ğŸ“ Define features (Step 2) ---\n",
    "    print(\" Defining features...\")\n",
    "    \n",
    "    # *** 3. Fixed: Initialize as empty list ***\n",
    "    continuous_cols = []\n",
    "    \n",
    "    # Categorical features are 40 attributes\n",
    "    # We exclude 'image_id'\n",
    "    # (Assume 'image_id' is the first column of .csv)\n",
    "    categorical_cols = df_master.columns.drop(['image_id']).tolist()\n",
    "    \n",
    "    # Ensure the label we selected is in the categorical feature list (will be removed later)\n",
    "    if label_column not in categorical_cols:\n",
    "        print(f\"Error: Label '{label_column}' is not in the attribute list.\")\n",
    "        print(f\"Available attributes: {categorical_cols}\")\n",
    "        return\n",
    "        \n",
    "    # Define non-feature columns\n",
    "    # *** 4. Modified: Removed 'split' ***\n",
    "    non_feature_cols = ['image_id', label_column]\n",
    "    \n",
    "    print(f\" > Defined {len(continuous_cols)} continuous features.\")\n",
    "    print(f\" > Defined {len(categorical_cols)} categorical features (including label).\")\n",
    "    print(f\" > Target label (Label): {label_column}\")\n",
    "\n",
    "    # --- 8. ğŸ”ª Dataset splitting (Step 8) ---\n",
    "    # *** 5. Completely modified: Use 8:1:1 stratified split, replacing original fixed split ***\n",
    "    print(f\" Performing 8:1:1 stratified split on {label_column}...\")\n",
    "    \n",
    "    # First, stratified split to get 80% training set\n",
    "    train_df, temp_df = train_test_split(\n",
    "        df_master,\n",
    "        test_size=0.2,\n",
    "        stratify=df_master[label_column],\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Then, split the remaining 20% equally into 10% validation set and 10% test set\n",
    "    val_df, test_df = train_test_split(\n",
    "        temp_df,\n",
    "        test_size=0.5,\n",
    "        stratify=temp_df[label_column],\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    print(f\" > Training set: {len(train_df)} samples\")\n",
    "    print(f\" > Validation set: {len(val_df)} samples\")\n",
    "    print(f\" > Test set: {len(test_df)} samples\")\n",
    "\n",
    "    # --- 3. ğŸ§¹ Feature filtering (Step 3) ---\n",
    "    # (This step logic still applies to the new split)\n",
    "    print(\" Filtering constant features...\")\n",
    "    \n",
    "    final_continuous_cols = list(continuous_cols)\n",
    "    final_categorical_cols = list(categorical_cols)\n",
    "    \n",
    "    # (This part of code unchanged, but now applies to newly split dataset)\n",
    "    for col in continuous_cols:\n",
    "        is_constant_train = train_df[col].nunique() <= 1\n",
    "        is_constant_test = test_df[col].nunique() <= 1\n",
    "        if is_constant_train and is_constant_test:\n",
    "            print(f\" > Removing constant continuous feature: {col}\")\n",
    "            final_continuous_cols.remove(col)\n",
    "            \n",
    "    for col in categorical_cols:\n",
    "        is_constant_train = train_df[col].nunique() <= 1\n",
    "        is_constant_test = test_df[col].nunique() <= 1\n",
    "        if is_constant_train and is_constant_test:\n",
    "            print(f\" > Removing constant categorical feature: {col}\")\n",
    "            final_categorical_cols.remove(col)\n",
    "            \n",
    "    # Ensure target label(label_column) is not treated as a feature\n",
    "    if label_column in final_categorical_cols:\n",
    "        final_categorical_cols.remove(label_column)\n",
    "        print(f\" > Isolated '{label_column}' as label, not as feature.\")\n",
    "        \n",
    "    print(f\" > Remaining {len(final_continuous_cols)} continuous features.\")\n",
    "    print(f\" > Remaining {len(final_categorical_cols)} categorical features (tabular attributes).\")\n",
    "\n",
    "    # --- 4. ğŸ—ºï¸ Path processing (Step 4) ---\n",
    "    print(\" Converting image paths to absolute paths...\")\n",
    "    \n",
    "    def create_absolute_path(image_id):\n",
    "        # Assume image_id is already a filename like '000001.jpg'\n",
    "        return os.path.join(base_image_dir, image_id)\n",
    "\n",
    "    train_df['absolute_image_path'] = train_df['image_id'].apply(create_absolute_path)\n",
    "    val_df['absolute_image_path'] = val_df['image_id'].apply(create_absolute_path)\n",
    "    test_df['absolute_image_path'] = test_df['image_id'].apply(create_absolute_path)\n",
    "    \n",
    "    non_feature_cols.extend(['absolute_image_path'])\n",
    "\n",
    "    # --- 5. ğŸ—‘ï¸ Data cleaning (Step 5) ---\n",
    "    print(\" Filtering invalid rows (based on paths and labels)...\")\n",
    "    initial_train, initial_val, initial_test = len(train_df), len(val_df), len(test_df)\n",
    "    \n",
    "    train_df = train_df.dropna(subset=['absolute_image_path', label_column])\n",
    "    val_df = val_df.dropna(subset=['absolute_image_path', label_column])\n",
    "    test_df = test_df.dropna(subset=['absolute_image_path', label_column])\n",
    "    \n",
    "    print(f\" > Training set removed {initial_train - len(train_df)} rows\")\n",
    "    print(f\" > Validation set removed {initial_val - len(val_df)} rows\")\n",
    "    print(f\" > Test set removed {initial_test - len(test_df)} rows\")\n",
    "\n",
    "    # --- 6. âœï¸ Fill missing values (Step 6) ---\n",
    "    print(\" Processing missing values/special encoding...\")\n",
    "\n",
    "    # (Continuous feature part skipped)\n",
    "    for col in final_continuous_cols:\n",
    "        mean_val = train_df[col].mean()\n",
    "        train_df[col] = train_df[col].fillna(mean_val)\n",
    "        val_df[col] = val_df[col].fillna(mean_val)\n",
    "        test_df[col] = test_df[col].fillna(mean_val)\n",
    "        \n",
    "    # **CelebA specific step**:\n",
    "    # *** 6. Assumption: We assume .csv still uses -1/1 encoding ***\n",
    "    # (If your .csv is already 0/1, you can comment out the .replace(-1, 0) line)\n",
    "    print(\" > [CelebA specific] Converting attributes: Map -1 to 0...\")\n",
    "    all_attr_cols = final_categorical_cols + [label_column]\n",
    "    for col in all_attr_cols:\n",
    "        train_df[col] = train_df[col].replace(-1, 0)\n",
    "        val_df[col] = val_df[col].replace(-1, 0)\n",
    "        test_df[col] = test_df[col].replace(-1, 0)\n",
    "        # No missing values, no need to process\n",
    "        \n",
    "    # --- 7. ğŸ”¢ Feature engineering (categorical) (Step 7) ---\n",
    "    print(\" Processing categorical features...\")\n",
    "    \n",
    "    # *** 7. Fixed: Initialize as empty list ***\n",
    "    field_lengths = []\n",
    "    \n",
    "    print(\" > CelebA attributes are already 0/1 encoded, skipping .cat.codes.\")\n",
    "    print(\" > Calculating cardinalities...\")\n",
    "\n",
    "    for col in final_categorical_cols:\n",
    "        all_values = pd.concat([train_df[col], val_df[col], test_df[col]])\n",
    "        cardinality = all_values.nunique()\n",
    "        # Add a check in case 'MISSING' was actually filled\n",
    "        if \"MISSING\" in all_values.unique():\n",
    "            print(f\" > Warning: Feature {col} contains 'MISSING' values.\")\n",
    "        field_lengths.append(cardinality)\n",
    "        \n",
    "    print(f\" > Cardinalities of {len(final_categorical_cols)} categorical features (partial): {field_lengths[:5]}...\")\n",
    "    \n",
    "    # --- 9. ğŸ”¢ Feature engineering (continuous) (Step 9) ---\n",
    "    print(\" Standardizing continuous features...\")\n",
    "\n",
    "    for _ in final_continuous_cols:\n",
    "        field_lengths.insert(0, 1) \n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    if final_continuous_cols:\n",
    "        scaler.fit(train_df[final_continuous_cols])\n",
    "        train_df[final_continuous_cols] = scaler.transform(train_df[final_continuous_cols])\n",
    "        val_df[final_continuous_cols] = scaler.transform(val_df[final_continuous_cols])\n",
    "        test_df[final_continuous_cols] = scaler.transform(test_df[final_continuous_cols])\n",
    "        print(\" > Continuous features standardized.\")\n",
    "    else:\n",
    "        print(\" > No continuous features, skipping standardization.\")\n",
    "\n",
    "    # --- 12. ğŸ–¼ï¸ Image processing (JPEG to NPY) (Step 12) ---\n",
    "    # *** 8. Modified: Added 224x224 Resize and fixed npy_path Bug ***\n",
    "    print(f\" Converting images (JPG -> NPY, and Resize to {IMAGE_SIZE}x{IMAGE_SIZE})...\")\n",
    "\n",
    "    def convert_jpg_to_npy(jpg_path):\n",
    "        \"\"\"\n",
    "        Open JPG, Resize, convert to NumPy array, save as .npy, and return .npy path\n",
    "        \"\"\"\n",
    "        if not os.path.exists(jpg_path):\n",
    "            warnings.warn(f\" > Warning: JPG file not found {jpg_path}. Skipping.\")\n",
    "            return None\n",
    "            \n",
    "        # *** 9. Fixed: Use [0] to get correct file basename ***\n",
    "        npy_path = os.path.splitext(jpg_path)[0] + \".npy\"\n",
    "        \n",
    "        if os.path.exists(npy_path):\n",
    "            return npy_path  # Skip existing files\n",
    "            \n",
    "        try:\n",
    "            with Image.open(jpg_path) as img:\n",
    "                # *** 10. New: Resize step ***\n",
    "                img_resized = img.resize((IMAGE_SIZE, IMAGE_SIZE), resample=LANCZOS_RESAMPLE)\n",
    "                \n",
    "                # Convert to NumPy array\n",
    "                if img_resized.mode == 'RGBA':\n",
    "                    img_resized = img_resized.convert('RGB')\n",
    "                    \n",
    "                img_array = np.array(img_resized)\n",
    "                np.save(npy_path, img_array)\n",
    "                return npy_path\n",
    "        except Exception as e:\n",
    "            warnings.warn(f\" > Warning: Error processing {jpg_path}: {e}. Skipping.\")\n",
    "            return None\n",
    "\n",
    "    non_feature_cols.extend(['npy_path'])\n",
    "    \n",
    "    tqdm.pandas(desc=\" > Converting training set images\")\n",
    "    train_df['npy_path'] = train_df['absolute_image_path'].progress_apply(convert_jpg_to_npy)\n",
    "    \n",
    "    tqdm.pandas(desc=\" > Converting validation set images\")\n",
    "    val_df['npy_path'] = val_df['absolute_image_path'].progress_apply(convert_jpg_to_npy)\n",
    "    \n",
    "    tqdm.pandas(desc=\" > Converting test set images\")\n",
    "    test_df['npy_path'] = test_df['absolute_image_path'].progress_apply(convert_jpg_to_npy)\n",
    "\n",
    "    # Clean again: discard failed conversions\n",
    "    train_df = train_df.dropna(subset=['npy_path'])\n",
    "    val_df = val_df.dropna(subset=['npy_path'])\n",
    "    test_df = test_df.dropna(subset=['npy_path'])\n",
    "    \n",
    "    print(\" > Image conversion completed.\")\n",
    "\n",
    "    # --- 10, 11, 12. ğŸ’¾ Save output ---\n",
    "    print(\"[Final] Saving all processed files...\")\n",
    "\n",
    "    final_feature_columns = final_continuous_cols + final_categorical_cols\n",
    "    \n",
    "    data_splits = {\n",
    "        'train': train_df,\n",
    "        'val': val_df,\n",
    "        'test': test_df\n",
    "    }\n",
    "    \n",
    "    for split_name, df in data_splits.items():\n",
    "        \n",
    "        # (Step 10) Save tabular features\n",
    "        features_path = os.path.join(output_dir, f\"{split_name}_features.csv\")\n",
    "        df[final_feature_columns].to_csv(features_path, index=False, header=False)\n",
    "        \n",
    "        # (Step 11) Save labels\n",
    "        labels_path = os.path.join(output_dir, f\"{split_name}_labels.pt\")\n",
    "        labels_tensor = torch.tensor(df[label_column].values, dtype=torch.int64)\n",
    "        torch.save(labels_tensor, labels_path)\n",
    "        \n",
    "        # (Step 12) Save image paths\n",
    "        paths_path = os.path.join(output_dir, f\"{split_name}_paths.pt\")\n",
    "        npy_path_list = df['npy_path'].tolist()\n",
    "        torch.save(npy_path_list, paths_path)\n",
    "\n",
    "    # (Step 10) Save field lengths\n",
    "    lengths_path = os.path.join(output_dir, \"tabular_lengths.pt\")\n",
    "    torch.save(field_lengths, lengths_path)\n",
    "\n",
    "    print(\"-\" * 30)\n",
    "    print(\"ğŸ‰ Preprocessing completed! ğŸ‰\")\n",
    "    print(f\"Output files saved to: {output_dir}\")\n",
    "    print(f\" > Label: {label_column}\")\n",
    "    print(f\" > Tabular features: {len(final_feature_columns)} other attributes\")\n",
    "    print(f\" > Split ratio: 8:1:1 (stratified)\")\n",
    "    print(f\" > Image processing: Resized to {IMAGE_SIZE}x{IMAGE_SIZE} and converted to .npy\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run main preprocessing function\n",
    "    preprocess_celeba_flow(\n",
    "        attr_file=ATTR_FILE,\n",
    "        base_image_dir=BASE_IMAGE_DIR,\n",
    "        output_dir=OUTPUT_DIR,\n",
    "        label_column=LABEL_COLUMN\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cc1673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ–‡ä»¶ä¸­æ˜¯å¦å­˜åœ¨NaNå€¼: False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "# ================================================================\n",
    "# 1. Please replace this with your CelebA .csv file path\n",
    "# ================================================================\n",
    "# Example:\n",
    "# path_to_your_csv = '/path/to/your/celeba_tabular_data.csv'\n",
    "path_to_your_csv = '/mnt/hdd/jiazy/CelebA/list_attr_celeba.csv'\n",
    "# ================================================================\n",
    "\n",
    "# Replace 'your_file.csv' with your filename\n",
    "df = pd.read_csv(path_to_your_csv)\n",
    "has_nan = df.isnull().values.any()\n",
    "print(f\"Does the file contain NaN values: {has_nan}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "charms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
