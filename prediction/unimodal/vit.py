import os
import sys
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
import pandas as pd
import numpy as np
import timm
from sklearn.metrics import (accuracy_score, f1_score, roc_auc_score, 
                             mean_squared_error, mean_absolute_error, r2_score)
import hydra
from hydra import initialize, compose
from hydra.utils import get_original_cwd, to_absolute_path
from omegaconf import DictConfig, OmegaConf
from tqdm import tqdm

import copy

class EarlyStopping:
    def __init__(self, patience=5, min_delta=0, mode='min', save_path='checkpoint/best_model.pth'):
        """
        Args:
            patience (int): åœ¨æŒ‡å®šæ¬¡æ•°å†…æŒ‡æ ‡æœªæ”¹å–„åˆ™åœæ­¢è®­ç»ƒ
            min_delta (float): æŒ‡æ ‡æ”¹å–„çš„æœ€å°é˜ˆå€¼
            mode (str): 'min' (å¦‚ loss/rmse) æˆ– 'max' (å¦‚ accuracy/r2)
            save_path (str): æœ€ä½³æ¨¡å‹æƒé‡çš„ä¿å­˜è·¯å¾„
        """
        self.patience = patience
        self.min_delta = min_delta
        self.mode = mode
        self.save_path = save_path
        self.counter = 0
        self.best_score = None
        self.early_stop = False
        
        # ç¡®ä¿ checkpoint ç›®å½•å­˜åœ¨
        checkpoint_dir = os.path.dirname(self.save_path)
        if checkpoint_dir and not os.path.exists(checkpoint_dir):
            os.makedirs(checkpoint_dir, exist_ok=True)

    def __call__(self, current_score, model):
        if self.best_score is None:
            self.best_score = current_score
            self.save_checkpoint(model)
        else:
            if self.mode == 'min':
                improved = current_score < (self.best_score - self.min_delta)
            else:
                improved = current_score > (self.best_score + self.min_delta)

            if improved:
                self.best_score = current_score
                self.save_checkpoint(model)
                self.counter = 0
            else:
                self.counter += 1
                if self.counter >= self.patience:
                    self.early_stop = True

    def save_checkpoint(self, model):
        """å°†æ¨¡å‹æƒé‡ä¿å­˜åˆ°ç¡¬ç›˜"""
        torch.save(model.state_dict(), self.save_path)

# --- 1. è‡ªå®šä¹‰æ•°æ®é›†ç±»ï¼šå¤„ç†è·¯å¾„æ–‡ä»¶ ---
class ImageDataset(Dataset):
    def __init__(self, paths_pt, labels_pt, transform=None):
        self.img_paths = torch.load(paths_pt)
        self.labels = torch.load(labels_pt)
        self.transform = transform

        if isinstance(self.labels, torch.Tensor):
            self.labels = self.labels.cpu().numpy()

    def __len__(self):
        return len(self.img_paths)

    def _npy_to_pil_rgb(self, img_array: np.ndarray) -> Image.Image:
        """
        æŠŠ npy è¯»å‡ºæ¥çš„ array è½¬æˆ PIL RGBï¼Œæ–¹ä¾¿èµ° torchvision transforms åš 224 resize/cropã€‚
        æ”¯æŒ (H,W), (H,W,1), (H,W,3), (C,H,W) ä¸” C=1/3ã€‚
        """
        arr = img_array

        # å»æ‰å¤šä½™ç»´åº¦ï¼ˆæ¯”å¦‚ (H,W,1)ï¼‰
        if arr.ndim == 3 and arr.shape[-1] == 1:
            arr = arr[:, :, 0]

        # (C,H,W) -> (H,W,C)
        if arr.ndim == 3 and arr.shape[0] in (1, 3) and arr.shape[-1] not in (1, 3):
            arr = np.transpose(arr, (1, 2, 0))

        # ç°åº¦ (H,W) -> (H,W,3)
        if arr.ndim == 2:
            arr = np.stack([arr, arr, arr], axis=-1)

        # å•é€šé“ (H,W,1) -> (H,W,3)
        if arr.ndim == 3 and arr.shape[-1] == 1:
            arr = np.repeat(arr, 3, axis=-1)

        # ä¿è¯æ˜¯ float
        arr = arr.astype(np.float32)

        # æŠŠæ•°å€¼å‹åˆ° [0,255] ä»¥æ„é€  PILï¼ˆè¿™é‡Œå°½é‡åšå¾—ç¨³å¥ï¼‰
        # å¦‚æœä½ çš„ npy æœ¬æ¥å°±æ˜¯ 0~1ï¼šä¹˜255
        # å¦‚æœæœ¬æ¥æ˜¯ 0~255ï¼šä¿æŒ
        # å¦åˆ™åš min-max å½’ä¸€åŒ–
        a_min, a_max = float(arr.min()), float(arr.max())
        if a_max <= 1.0 and a_min >= 0.0:
            arr = arr * 255.0
        elif a_max > 255.0 or a_min < 0.0:
            eps = 1e-6
            arr = (arr - a_min) / (a_max - a_min + eps) * 255.0

        arr = np.clip(arr, 0, 255).astype(np.uint8)

        return Image.fromarray(arr, mode="RGB")

    def __getitem__(self, idx):
        img_path = self.img_paths[idx]
        label = self.labels[idx]

        if str(img_path).endswith(".npy"):
            img_array = np.load(img_path)
            image = self._npy_to_pil_rgb(img_array)

            if self.transform is not None:
                image = self.transform(image)
            else:
                # æ²¡ç»™ transform ä¹Ÿè‡³å°‘è½¬æˆ tensorï¼Œé¿å…å‡ºé”™
                image = torch.from_numpy(np.array(image)).permute(2, 0, 1).float() / 255.0
        else:
            image = Image.open(img_path).convert("RGB")
            if self.transform is not None:
                image = self.transform(image)

        return image, torch.tensor(label, dtype=torch.long)
    
# --- 2. è®­ç»ƒä¸éªŒè¯å•è½®é€»è¾‘ ---
def train_one_epoch(model, loader, optimizer, scheduler, criterion, device, task):
    model.train()
    running_loss = 0.0
    for images, labels in loader:
        images, labels = images.to(device), labels.to(device)
        
        optimizer.zero_grad()
        outputs = model(images)
        
        if task == 'regression':
            labels = labels.float().view(-1, 1)
            loss = criterion(outputs, labels)
        else:
            loss = criterion(outputs, labels.long())
            
        loss.backward()
        optimizer.step()
        scheduler.step()
        running_loss += loss.item()
    return running_loss / len(loader)

@torch.no_grad()
def evaluate(model, loader, device, task, num_classes):
    model.eval()
    all_preds = []
    all_labels = []
    all_probs = []

    for images, labels in loader:
        images = images.to(device)
        outputs = model(images)
        
        if task == 'regression':
            all_preds.extend(outputs.cpu().numpy())
            all_labels.extend(labels.numpy())
        else:
            probs = torch.softmax(outputs, dim=1)
            preds = torch.argmax(probs, dim=1)
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.numpy())
            all_probs.extend(probs.cpu().numpy())

    all_preds = np.array(all_preds)
    all_labels = np.array(all_labels)
    
    if task == 'classification':
        acc = accuracy_score(all_labels, all_preds)
        f1 = f1_score(all_labels, all_preds, average='macro')
        if num_classes == 2:
            auc = roc_auc_score(all_labels, np.array(all_probs)[:, 1])
        else:
            auc = roc_auc_score(all_labels, all_probs, multi_class='ovr', average='macro')
        return {"acc": acc, "auc": auc, "f1": f1}
    else:
        rmse = np.sqrt(mean_squared_error(all_labels, all_preds))
        mae = mean_absolute_error(all_labels, all_preds)
        r2 = r2_score(all_labels, all_preds)
        return {"rmse": rmse, "mae": mae, "r2": r2}

# --- 3. æ ¸å¿ƒå®éªŒè¿è¡Œå‡½æ•° (è¶…å‚æœç´¢) ---
def run_vit_experiment(cfg: DictConfig, train_data_info, val_data_info, seed, target):
    torch.manual_seed(seed)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    task = cfg.get('task', 'classification')
    num_classes = cfg.get('num_classes', 1 if task == 'regression' else 2)

    # æ•°æ®å‡†å¤‡ (ä¿æŒä¸å˜)
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ])
    train_dataset = ImageDataset(train_data_info['paths'], train_data_info['labels'], transform=transform)
    val_dataset = ImageDataset(val_data_info['paths'], val_data_info['labels'], transform=transform)
    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)
    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)

    # æœç´¢èŒƒå›´
    lrs = [5e-4, 1e-3, 3e-3]
    wds = [0.03, 0.1, 0.3]
    epochs_list = [50, 100, 500]

    global_best_val_score = -float('inf') if task == 'classification' else float('inf')
    global_best_results = None
    global_best_params = {}

    for lr in lrs:
        for wd in wds:
            for max_epochs in epochs_list:
                print(f"--- å°è¯•é…ç½®: LR={lr}, WD={wd}, MaxEpochs={max_epochs} ---")
                
                model = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=num_classes).to(device)
                optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)
                
                # Warmup è®¾ç½®
                total_steps = len(train_loader) * max_epochs
                scheduler = optim.lr_scheduler.LinearLR(optimizer, start_factor=0.01, total_iters=int(0.1 * total_steps))
                criterion = nn.MSELoss() if task == 'regression' else nn.CrossEntropyLoss()

                # ä¸ºå½“å‰è¶…å‚ç»„åˆå®šä¹‰å”¯ä¸€çš„ä¿å­˜è·¯å¾„
                current_ckpt_path = f"/data1/jiazy/checkpoint/{target}/vit_s{seed}_lr{lr}_wd{wd}_ep{max_epochs}.pth"
                
                early_stopper = EarlyStopping(
                    patience=5, 
                    mode='max' if task == 'classification' else 'min',
                    save_path=current_ckpt_path
                )

                for epoch in range(max_epochs):
                    _ = train_one_epoch(model, train_loader, optimizer, scheduler, criterion, device, task)
                    metrics = evaluate(model, val_loader, device, task, num_classes)
                    
                    current_score = metrics['acc'] if task == 'classification' else metrics['rmse']
                    early_stopper(current_score, model)

                    if early_stopper.early_stop:
                        print(f"      [æ—©åœ] è§¦å‘äº Epoch {epoch}ã€‚")
                        break
                
                # --- æ ¸å¿ƒä¿®æ”¹ï¼šä»ç¡¬ç›˜åŠ è½½è¯¥é…ç½®ä¸‹çš„æœ€ä½³æƒé‡ ---
                if os.path.exists(current_ckpt_path):
                    model.load_state_dict(torch.load(current_ckpt_path))
                
                final_metrics = evaluate(model, val_loader, device, task, num_classes)

                # æ›´æ–°å…¨å±€æœ€ä¼˜è¶…å‚æ•°
                is_global_better = False
                if task == 'classification':
                    if final_metrics['acc'] > global_best_val_score:
                        global_best_val_score = final_metrics['acc']
                        is_global_better = True
                else:
                    if final_metrics['rmse'] < global_best_val_score:
                        global_best_val_score = final_metrics['rmse']
                        is_global_better = True

                if is_global_better:
                    global_best_results = final_metrics
                    global_best_params = {"lr": lr, "wd": wd, "actual_epochs": epoch + 1}

    # æ ¼å¼åŒ–è¾“å‡º
    if task == 'classification':
        result_line = f"acc:{global_best_results['acc']:.4f},auc:{global_best_results['auc']:.4f},macro-F1:{global_best_results['f1']:.4f}"
    else:
        result_line = f"rmse:{global_best_results['rmse']:.4f},mae:{global_best_results['mae']:.4f},r2:{global_best_results['r2']:.4f}"

    return result_line, global_best_params

def call_vit_with_config(config_name: str):
    """
    ViT å®éªŒçš„å‡½æ•°å¼è°ƒç”¨æ¥å£ã€‚
    """
    # 1. ä½¿ç”¨ Compose API åˆå§‹åŒ–é…ç½®
    # æ³¨æ„ï¼šconfig_path éœ€æŒ‡å‘å­˜æ”¾ .yaml æ–‡ä»¶çš„çœŸå®ç›®å½•
    with initialize(version_base=None, config_path="../configs"):
        cfg = compose(config_name=config_name)
    
    # 2. è°ƒç”¨æ ¸å¿ƒé€»è¾‘
    return run_vit_task(cfg)

def run_vit_task(cfg: DictConfig):
    """
    ViT è·¯å¾„è§£æã€å¤šç§å­è¿è¡ŒåŠç»“æœè®°å½•çš„æ ¸å¿ƒé€»è¾‘ã€‚
    """
    # --- 1. è·¯å¾„è§£æé€»è¾‘ ---
    print("--- 1.A. æ­£åœ¨è§£æå›¾åƒæ•°æ®è·¯å¾„ ---")
    data_root = cfg.get('data_base')
    path_keys = [
        'data_train_eval_imaging', 'labels_train_eval_imaging',
        'data_val_eval_imaging', 'labels_val_eval_imaging',
        'data_test_eval_imaging', 'labels_test_eval_imaging'
    ]
    
    if data_root:
        print(f"    æ£€æµ‹åˆ° 'data_root': {data_root}ï¼Œæ­£åœ¨æ›´æ–°è·¯å¾„...")
        for key in path_keys:
            if key in cfg and cfg[key] is not None:
                # æ‹¼æ¥ç»å¯¹è·¯å¾„
                cfg[key] = os.path.join(data_root, cfg[key])
    else:
        print("    æœªæä¾› 'data_root'ï¼Œä½¿ç”¨åŸå§‹è·¯å¾„ã€‚")

    # --- 2. åŠ¨æ€ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å ---
    target = cfg.get('target', 'default') 
    output_filename = f'result/vit_results_{target}.txt'
    
    print(f"\n--- å®éªŒç›®æ ‡: {target} ---")
    print(f"ç»“æœå°†ä¿å­˜è‡³: {output_filename}")

    # å‡†å¤‡è®­ç»ƒå’ŒéªŒè¯ä¿¡æ¯
    train_info = {
        'paths': cfg.get('data_train_eval_imaging'), 
        'labels': cfg.get('labels_train_eval_imaging')
    }
    val_info = {
        'paths': cfg.get('data_val_eval_imaging'), 
        'labels': cfg.get('labels_val_eval_imaging')
    }

    # 3. è¿è¡Œå®éªŒå¹¶å†™å…¥ç»“æœ
    seeds = [2022, 2023, 2024]
    os.makedirs(os.path.dirname(output_filename), exist_ok=True)

    

    with open(output_filename, 'a') as f:
        f.write(f"--- æœ€ç»ˆé…ç½® (Target: {target}, Model: ViT) ---\n")
        f.write(OmegaConf.to_yaml(cfg))
        f.write("-" * 30 + "\n\n")

        for seed in seeds:
            print(f"ğŸš€ æ­£åœ¨è¿è¡Œéšæœºç§å­: {seed}...")
            # æ‰§è¡Œå…·ä½“çš„ ViT è®­ç»ƒ/è¯„æµ‹é€»è¾‘
            result_line, best_params = run_vit_experiment(cfg, train_info, val_info, seed, target)
            
            # è®°å½•åˆ°æ–‡ä»¶
            f.write(f"seed:{seed}\n")
            f.write(f"best_params: {best_params}\n")
            f.write(result_line + "\n\n")

    print(f"\nViT å®éªŒå®Œæˆã€‚ç»“æœå·²è¿½åŠ è‡³: {output_filename}")
    return output_filename

if __name__ == "__main__":
    main()